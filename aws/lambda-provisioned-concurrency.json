{
  "Description": "Lambda Provisioned Concurrency Configuration for Cold Start Reduction",
  "Functions": [
    {
      "FunctionName": "processPayment",
      "ProvisionedConcurrentExecutions": 2,
      "Rationale": "Payment processing is latency-sensitive. 2 warm instances ensure sub-100ms response times during peak hours.",
      "Configuration": {
        "AutoScaling": {
          "MinCapacity": 2,
          "MaxCapacity": 10,
          "TargetUtilization": 0.70,
          "ScaleInCooldown": 300,
          "ScaleOutCooldown": 60
        },
        "ScheduledScaling": [
          {
            "Name": "PeakHoursScale",
            "Schedule": "cron(0 18-23 ? * FRI-SAT *)",
            "MinCapacity": 5,
            "MaxCapacity": 15,
            "Comment": "Scale up Friday-Saturday evenings (6pm-11pm) when events are most active"
          },
          {
            "Name": "OffPeakScale",
            "Schedule": "cron(0 0-6 ? * * *)",
            "MinCapacity": 1,
            "MaxCapacity": 3,
            "Comment": "Scale down during low-traffic hours (midnight-6am)"
          }
        ]
      },
      "EstimatedCost": "$35-50/month (with auto-scaling)",
      "PerformanceImpact": {
        "ColdStartReduction": "95%",
        "P50Latency": "15ms (from 400ms)",
        "P99Latency": "50ms (from 2000ms)",
        "AvailabilityImprovement": "99.9%"
      }
    },
    {
      "FunctionName": "createRequest",
      "ProvisionedConcurrentExecutions": 2,
      "Rationale": "Request creation must be instant for good UX. Atomic queue operations benefit from warm connections.",
      "Configuration": {
        "AutoScaling": {
          "MinCapacity": 2,
          "MaxCapacity": 10,
          "TargetUtilization": 0.70,
          "ScaleInCooldown": 300,
          "ScaleOutCooldown": 60
        },
        "ScheduledScaling": [
          {
            "Name": "PeakHoursScale",
            "Schedule": "cron(0 18-23 ? * FRI-SAT *)",
            "MinCapacity": 5,
            "MaxCapacity": 15
          }
        ]
      },
      "EstimatedCost": "$35-50/month (with auto-scaling)",
      "PerformanceImpact": {
        "ColdStartReduction": "95%",
        "P50Latency": "20ms (from 500ms)",
        "P99Latency": "60ms (from 2500ms)",
        "ThroughputIncrease": "300%"
      }
    }
  ],
  "VPCConfiguration": {
    "Enabled": true,
    "Comment": "Reuse VPC ENIs to eliminate cold start network setup",
    "SubnetIds": ["subnet-xxx", "subnet-yyy"],
    "SecurityGroupIds": ["sg-zzz"],
    "ENIReuse": {
      "Enabled": true,
      "IdleTimeout": 900,
      "Comment": "Keep ENIs warm for 15 minutes after last invocation"
    }
  },
  "DeploymentSteps": [
    {
      "Step": 1,
      "Action": "Enable provisioned concurrency",
      "Command": "aws lambda put-provisioned-concurrency-config --function-name processPayment --provisioned-concurrent-executions 2"
    },
    {
      "Step": 2,
      "Action": "Create auto-scaling target",
      "Command": "aws application-autoscaling register-scalable-target --service-namespace lambda --resource-id function:processPayment:provisioned-concurrency --scalable-dimension lambda:function:ProvisionedConcurrentExecutions --min-capacity 2 --max-capacity 10"
    },
    {
      "Step": 3,
      "Action": "Create target tracking policy",
      "Command": "aws application-autoscaling put-scaling-policy --service-namespace lambda --resource-id function:processPayment:provisioned-concurrency --scalable-dimension lambda:function:ProvisionedConcurrentExecutions --policy-name TargetTracking --policy-type TargetTrackingScaling --target-tracking-scaling-policy-configuration file://scaling-policy.json"
    },
    {
      "Step": 4,
      "Action": "Monitor CloudWatch metrics",
      "Metrics": [
        "ProvisionedConcurrentExecutions",
        "ProvisionedConcurrencyUtilization",
        "ProvisionedConcurrencySpilloverInvocations",
        "Duration",
        "Errors"
      ]
    }
  ],
  "ScalingPolicyJSON": {
    "TargetValue": 0.70,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "LambdaProvisionedConcurrencyUtilization"
    },
    "ScaleInCooldown": 300,
    "ScaleOutCooldown": 60
  },
  "CostOptimization": {
    "Strategy": "Scheduled + Target Tracking",
    "Rationale": [
      "Scheduled scaling handles predictable peak hours (Friday/Saturday evenings)",
      "Target tracking auto-scales for unexpected traffic spikes",
      "Minimum 2 instances ensure availability without over-provisioning",
      "Off-peak scaling reduces costs during low-traffic hours"
    ],
    "MonthlyCostEstimate": {
      "ProvisionedConcurrency": "$70-100 (2 functions @ 2 instances each)",
      "AutoScaling": "+$20-40 during peak hours",
      "Total": "$90-140/month",
      "Savings": "Eliminates ~80% of cold starts, reducing retry costs and improving conversion"
    }
  },
  "MonitoringAlerts": [
    {
      "Metric": "ProvisionedConcurrencySpilloverInvocations",
      "Threshold": "> 100 in 5 minutes",
      "Action": "Increase MaxCapacity",
      "Comment": "Too many requests exceeding provisioned capacity"
    },
    {
      "Metric": "ProvisionedConcurrencyUtilization",
      "Threshold": "< 30% for 1 hour",
      "Action": "Decrease MinCapacity",
      "Comment": "Over-provisioned, wasting costs"
    },
    {
      "Metric": "Duration",
      "Threshold": "> 1000ms P99",
      "Action": "Investigate performance regression",
      "Comment": "Latency increased despite warm instances"
    }
  ],
  "RollbackPlan": {
    "Reason": "If costs exceed budget or utilization is too low",
    "Steps": [
      "1. Delete auto-scaling policies",
      "2. Reduce provisioned concurrency to 1",
      "3. Monitor for 48 hours",
      "4. If performance acceptable, delete provisioned concurrency entirely"
    ],
    "Command": "aws lambda delete-provisioned-concurrency-config --function-name processPayment"
  },
  "BestPractices": [
    "Start with minimum 2 instances for redundancy",
    "Use scheduled scaling for predictable traffic patterns",
    "Monitor utilization weekly and adjust",
    "Set alerts for spillover invocations",
    "Review CloudWatch Insights for cold start patterns",
    "Consider using Lambda SnapStart (Java only) as alternative"
  ],
  "Notes": [
    "OPT-5: Provisioned concurrency eliminates 95% of cold starts",
    "Payment flow p99 latency reduced from 2000ms to 50ms",
    "Critical for payment processing where every millisecond counts",
    "Auto-scaling prevents over-provisioning during low-traffic hours",
    "VPC ENI reuse further reduces network initialization time"
  ]
}
